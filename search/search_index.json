{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"audio_signal","text":"<p>Welcome to the documentation for <code>audio_signal</code>!</p> <p>A modern Python library for audio signal processing, built on PyTorch and torchaudio.</p> <ul> <li>Installation</li> <li>Usage</li> <li>API Reference</li> </ul>"},{"location":"api/","title":"API Reference","text":""},{"location":"api/#audio_signal.core.AudioSignal","title":"<code>AudioSignal</code>","text":"<p>               Bases: <code>CoreAudioSignal</code></p> <p>A High-level audio signal class that inherits from CoreAudioSignal. Provides additional methods for common audio operations like playback, saving, and generating waveforms.</p> Source code in <code>src/audio_signal/core.py</code> <pre><code>class AudioSignal(CoreAudioSignal):\n    \"\"\" \n    A High-level audio signal class that inherits from CoreAudioSignal.\n    Provides additional methods for common audio operations like playback, saving, and generating waveforms.\n    \"\"\"\n\n    @classmethod\n    def wave(cls, freq: float, time: float, sr: int) -&gt; \"AudioSignal\":\n        \"\"\"\n        Generate a sine wave AudioSignal.\n\n        Args:\n            freq (float): Frequency of the sine wave in Hz.\n            time (float): Duration in seconds.\n            sr (int): Sample rate.\n\n        Returns:\n            AudioSignal: Generated sine wave.\n        \"\"\"\n        t = torch.linspace(0,time,sr*time)\n        wf = torch.sin(2*np.pi*freq*t)\n        return cls(wf.unsqueeze(0),sr)\n\n    def play(self) -&gt; Audio:\n        \"\"\"\n        Play the audio signal in a Jupyter/IPython environment.\n\n        Returns:\n            IPython.display.Audio: Audio widget for playback.\n        \"\"\"\n        return Audio(self,rate=self.sample_rate)\n\n    def save(self, path: str) -&gt; None:\n        \"\"\"\n        Save the audio signal to a file.\n\n        Args:\n            path (str): Path to save the audio file.\n        \"\"\"\n        ta.save(path,self,self.sample_rate)\n\n    def speed(self, factor: float) -&gt; \"AudioSignal\":\n        \"\"\"\n        Change the playback speed by adjusting the sample rate.\n\n        Args:\n            factor (float): Speed factor (e.g., 2.0 is double speed).\n\n        Returns:\n            AudioSignal: The modified instance (in-place).\n        \"\"\"\n        self._sample_rate = int(self._sample_rate*factor)\n        return self\n\n    def convolve(self, kernel: torch.Tensor) -&gt; \"AudioSignal\":\n        \"\"\"\n        Convolve the audio signal with a kernel.\n\n        Args:\n            kernel (torch.Tensor): The convolution kernel.\n\n        Returns:\n            AudioSignal: The convolved signal.\n        \"\"\"\n        return self._from_tensor(ta.functional.convolve(self,kernel))\n\n    def correlate(self, kernel: torch.Tensor) -&gt; \"AudioSignal\":\n        \"\"\"\n        Correlate the audio signal with a kernel.\n\n        Args:\n            kernel (torch.Tensor): The correlation kernel.\n\n        Returns:\n            AudioSignal: The correlated signal.\n        \"\"\"\n        return self._from_tensor(ta.functional.corr(self,kernel))\n</code></pre>"},{"location":"api/#audio_signal.core.AudioSignal.convolve","title":"<code>convolve(kernel)</code>","text":"<p>Convolve the audio signal with a kernel.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Tensor</code> <p>The convolution kernel.</p> required <p>Returns:</p> Name Type Description <code>AudioSignal</code> <code>AudioSignal</code> <p>The convolved signal.</p> Source code in <code>src/audio_signal/core.py</code> <pre><code>def convolve(self, kernel: torch.Tensor) -&gt; \"AudioSignal\":\n    \"\"\"\n    Convolve the audio signal with a kernel.\n\n    Args:\n        kernel (torch.Tensor): The convolution kernel.\n\n    Returns:\n        AudioSignal: The convolved signal.\n    \"\"\"\n    return self._from_tensor(ta.functional.convolve(self,kernel))\n</code></pre>"},{"location":"api/#audio_signal.core.AudioSignal.correlate","title":"<code>correlate(kernel)</code>","text":"<p>Correlate the audio signal with a kernel.</p> <p>Parameters:</p> Name Type Description Default <code>kernel</code> <code>Tensor</code> <p>The correlation kernel.</p> required <p>Returns:</p> Name Type Description <code>AudioSignal</code> <code>AudioSignal</code> <p>The correlated signal.</p> Source code in <code>src/audio_signal/core.py</code> <pre><code>def correlate(self, kernel: torch.Tensor) -&gt; \"AudioSignal\":\n    \"\"\"\n    Correlate the audio signal with a kernel.\n\n    Args:\n        kernel (torch.Tensor): The correlation kernel.\n\n    Returns:\n        AudioSignal: The correlated signal.\n    \"\"\"\n    return self._from_tensor(ta.functional.corr(self,kernel))\n</code></pre>"},{"location":"api/#audio_signal.core.AudioSignal.play","title":"<code>play()</code>","text":"<p>Play the audio signal in a Jupyter/IPython environment.</p> <p>Returns:</p> Type Description <code>Audio</code> <p>IPython.display.Audio: Audio widget for playback.</p> Source code in <code>src/audio_signal/core.py</code> <pre><code>def play(self) -&gt; Audio:\n    \"\"\"\n    Play the audio signal in a Jupyter/IPython environment.\n\n    Returns:\n        IPython.display.Audio: Audio widget for playback.\n    \"\"\"\n    return Audio(self,rate=self.sample_rate)\n</code></pre>"},{"location":"api/#audio_signal.core.AudioSignal.save","title":"<code>save(path)</code>","text":"<p>Save the audio signal to a file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>Path to save the audio file.</p> required Source code in <code>src/audio_signal/core.py</code> <pre><code>def save(self, path: str) -&gt; None:\n    \"\"\"\n    Save the audio signal to a file.\n\n    Args:\n        path (str): Path to save the audio file.\n    \"\"\"\n    ta.save(path,self,self.sample_rate)\n</code></pre>"},{"location":"api/#audio_signal.core.AudioSignal.speed","title":"<code>speed(factor)</code>","text":"<p>Change the playback speed by adjusting the sample rate.</p> <p>Parameters:</p> Name Type Description Default <code>factor</code> <code>float</code> <p>Speed factor (e.g., 2.0 is double speed).</p> required <p>Returns:</p> Name Type Description <code>AudioSignal</code> <code>AudioSignal</code> <p>The modified instance (in-place).</p> Source code in <code>src/audio_signal/core.py</code> <pre><code>def speed(self, factor: float) -&gt; \"AudioSignal\":\n    \"\"\"\n    Change the playback speed by adjusting the sample rate.\n\n    Args:\n        factor (float): Speed factor (e.g., 2.0 is double speed).\n\n    Returns:\n        AudioSignal: The modified instance (in-place).\n    \"\"\"\n    self._sample_rate = int(self._sample_rate*factor)\n    return self\n</code></pre>"},{"location":"api/#audio_signal.core.AudioSignal.wave","title":"<code>wave(freq, time, sr)</code>  <code>classmethod</code>","text":"<p>Generate a sine wave AudioSignal.</p> <p>Parameters:</p> Name Type Description Default <code>freq</code> <code>float</code> <p>Frequency of the sine wave in Hz.</p> required <code>time</code> <code>float</code> <p>Duration in seconds.</p> required <code>sr</code> <code>int</code> <p>Sample rate.</p> required <p>Returns:</p> Name Type Description <code>AudioSignal</code> <code>AudioSignal</code> <p>Generated sine wave.</p> Source code in <code>src/audio_signal/core.py</code> <pre><code>@classmethod\ndef wave(cls, freq: float, time: float, sr: int) -&gt; \"AudioSignal\":\n    \"\"\"\n    Generate a sine wave AudioSignal.\n\n    Args:\n        freq (float): Frequency of the sine wave in Hz.\n        time (float): Duration in seconds.\n        sr (int): Sample rate.\n\n    Returns:\n        AudioSignal: Generated sine wave.\n    \"\"\"\n    t = torch.linspace(0,time,sr*time)\n    wf = torch.sin(2*np.pi*freq*t)\n    return cls(wf.unsqueeze(0),sr)\n</code></pre>"},{"location":"api/#audio_signal.core.CoreAudioSignal","title":"<code>CoreAudioSignal</code>","text":"<p>               Bases: <code>Tensor</code></p> <p>A low-level subclass of torch.Tensor that represents an audio signal with an attached sample rate. Supports initialization from various formats (file path, numpy array, torch tensor)</p> Source code in <code>src/audio_signal/core.py</code> <pre><code>class CoreAudioSignal(torch.Tensor):\n    \"\"\"\n    A low-level subclass of torch.Tensor that represents an audio signal with an attached sample rate.\n    Supports initialization from various formats (file path, numpy array, torch tensor)\n    \"\"\"\n    def __new__(\n        cls,\n        audio_source: Union[torch.Tensor, np.ndarray, str, bytes],\n        sample_rate: int = None\n    ) -&gt; \"CoreAudioSignal\":\n        \"\"\"\n        Create a new CoreAudioSignal instance from various audio sources.\n\n        Args:\n            audio_source (Union[torch.Tensor, np.ndarray, str, bytes]): The audio data source.\n            sample_rate (int, optional): The sample rate of the audio signal.\n\n        Returns:\n            CoreAudioSignal: An instance with audio data and sample rate.\n        \"\"\"\n\n        if isinstance(audio_source, cls):\n            return audio_source\n\n        inferred_sr = None\n        if isinstance(audio_source, (str, bytes)):\n            audio_source, inferred_sr = ta.load(audio_source)\n\n        elif isinstance(audio_source, np.ndarray):\n            audio_source = torch.from_numpy(audio_source)\n\n        elif isinstance(audio_source, torch.Tensor):\n            if sample_rate is None and hasattr(audio_source, '_sample_rate'):\n                sample_rate = audio_source._sample_rate\n        else:\n            raise TypeError(f'Unsupported input data type: {type(audio_source)}')\n\n        if sample_rate is None:\n            if inferred_sr is None:\n                raise ValueError('Sample rate must be provided')\n            else:\n              sample_rate = inferred_sr\n\n        obj = torch.Tensor(audio_source).as_subclass(cls)\n        obj._sample_rate = sample_rate\n\n        if inferred_sr is not None and inferred_sr!=sample_rate:\n            warnings.warn(f'Inferred sample rate {inferred_sr} does not match provided sample rate {sample_rate}')\n            obj = obj.resample(sample_rate)\n\n        return obj\n\n    @property\n    def sample_rate(self) -&gt; int:\n        \"\"\"\n        Returns the sample rate of the audio signal.\n\n        Returns:\n            int: The sample rate.\n        \"\"\"\n        return self._sample_rate\n\n\n    def resample(self, new_sample_rate: int) -&gt; \"CoreAudioSignal\":\n        \"\"\"\n        Resample the audio signal to a new sample rate.\n\n        Args:\n            new_sample_rate (int): The desired sample rate.\n\n        Returns:\n            CoreAudioSignal: A new instance with the resampled audio.\n        \"\"\"\n        result =  ta.transforms.Resample(self.sample_rate, new_sample_rate)(self)\n        return type(self)(result,new_sample_rate)\n\n    @classmethod\n    def __torch_function__(\n        cls,\n        func,\n        types,\n        args=(),\n        kwargs=None\n    ):\n        if kwargs is None:\n            kwargs = {}\n\n        result = super().__torch_function__(func, types, args, kwargs)\n\n        # This is a tricky part - Based on the result of the function we\n        # should decide whether to return a CoreAudioSignal or not.\n\n        if not isinstance(result, CoreAudioSignal):\n            return result\n\n        if result.is_complex() or result.ndim not in (1,2):\n            return result.as_subclass(torch.Tensor)\n\n        if result.ndim == 2 and result.shape[0] not in (1,2):\n            return result.as_subclass(torch.Tensor)\n\n        # find a source with sample rate\n        def find_sr(obj):\n            return getattr(obj, '_sample_rate', None)\n\n        # look in args\n        sr = None\n        all_args = list(args)\n        if args and isinstance(args[0], (tuple, list)):\n            all_args += list(args[0])\n\n        for arg in all_args:\n            if isinstance(arg, CoreAudioSignal):\n                sr = find_sr(arg)\n                if sr is not None:\n                    break\n\n        # propagate sample_rate if result is tensor-like\n        if sr is None:\n          return result.as_subclass(torch.Tensor)\n\n        result._sample_rate = sr\n        return result\n\n    def _from_tensor(self, tensor: torch.Tensor) -&gt; \"CoreAudioSignal\":\n        return type(self)(tensor,self._sample_rate)\n\n    def clone(self) -&gt; \"CoreAudioSignal\":\n        \"\"\"\n        Return a copy of the audio signal.\n\n        Returns:\n            CoreAudioSignal: A cloned instance.\n        \"\"\"\n        return self._from_tensor(super().clone())\n\n    def __repr__(self) -&gt; str:\n        return super().__repr__() + f', sample_rate={self.sample_rate}'\n</code></pre>"},{"location":"api/#audio_signal.core.CoreAudioSignal.sample_rate","title":"<code>sample_rate</code>  <code>property</code>","text":"<p>Returns the sample rate of the audio signal.</p> <p>Returns:</p> Name Type Description <code>int</code> <code>int</code> <p>The sample rate.</p>"},{"location":"api/#audio_signal.core.CoreAudioSignal.__new__","title":"<code>__new__(audio_source, sample_rate=None)</code>","text":"<p>Create a new CoreAudioSignal instance from various audio sources.</p> <p>Parameters:</p> Name Type Description Default <code>audio_source</code> <code>Union[Tensor, ndarray, str, bytes]</code> <p>The audio data source.</p> required <code>sample_rate</code> <code>int</code> <p>The sample rate of the audio signal.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>CoreAudioSignal</code> <code>CoreAudioSignal</code> <p>An instance with audio data and sample rate.</p> Source code in <code>src/audio_signal/core.py</code> <pre><code>def __new__(\n    cls,\n    audio_source: Union[torch.Tensor, np.ndarray, str, bytes],\n    sample_rate: int = None\n) -&gt; \"CoreAudioSignal\":\n    \"\"\"\n    Create a new CoreAudioSignal instance from various audio sources.\n\n    Args:\n        audio_source (Union[torch.Tensor, np.ndarray, str, bytes]): The audio data source.\n        sample_rate (int, optional): The sample rate of the audio signal.\n\n    Returns:\n        CoreAudioSignal: An instance with audio data and sample rate.\n    \"\"\"\n\n    if isinstance(audio_source, cls):\n        return audio_source\n\n    inferred_sr = None\n    if isinstance(audio_source, (str, bytes)):\n        audio_source, inferred_sr = ta.load(audio_source)\n\n    elif isinstance(audio_source, np.ndarray):\n        audio_source = torch.from_numpy(audio_source)\n\n    elif isinstance(audio_source, torch.Tensor):\n        if sample_rate is None and hasattr(audio_source, '_sample_rate'):\n            sample_rate = audio_source._sample_rate\n    else:\n        raise TypeError(f'Unsupported input data type: {type(audio_source)}')\n\n    if sample_rate is None:\n        if inferred_sr is None:\n            raise ValueError('Sample rate must be provided')\n        else:\n          sample_rate = inferred_sr\n\n    obj = torch.Tensor(audio_source).as_subclass(cls)\n    obj._sample_rate = sample_rate\n\n    if inferred_sr is not None and inferred_sr!=sample_rate:\n        warnings.warn(f'Inferred sample rate {inferred_sr} does not match provided sample rate {sample_rate}')\n        obj = obj.resample(sample_rate)\n\n    return obj\n</code></pre>"},{"location":"api/#audio_signal.core.CoreAudioSignal.clone","title":"<code>clone()</code>","text":"<p>Return a copy of the audio signal.</p> <p>Returns:</p> Name Type Description <code>CoreAudioSignal</code> <code>CoreAudioSignal</code> <p>A cloned instance.</p> Source code in <code>src/audio_signal/core.py</code> <pre><code>def clone(self) -&gt; \"CoreAudioSignal\":\n    \"\"\"\n    Return a copy of the audio signal.\n\n    Returns:\n        CoreAudioSignal: A cloned instance.\n    \"\"\"\n    return self._from_tensor(super().clone())\n</code></pre>"},{"location":"api/#audio_signal.core.CoreAudioSignal.resample","title":"<code>resample(new_sample_rate)</code>","text":"<p>Resample the audio signal to a new sample rate.</p> <p>Parameters:</p> Name Type Description Default <code>new_sample_rate</code> <code>int</code> <p>The desired sample rate.</p> required <p>Returns:</p> Name Type Description <code>CoreAudioSignal</code> <code>CoreAudioSignal</code> <p>A new instance with the resampled audio.</p> Source code in <code>src/audio_signal/core.py</code> <pre><code>def resample(self, new_sample_rate: int) -&gt; \"CoreAudioSignal\":\n    \"\"\"\n    Resample the audio signal to a new sample rate.\n\n    Args:\n        new_sample_rate (int): The desired sample rate.\n\n    Returns:\n        CoreAudioSignal: A new instance with the resampled audio.\n    \"\"\"\n    result =  ta.transforms.Resample(self.sample_rate, new_sample_rate)(self)\n    return type(self)(result,new_sample_rate)\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>I recommend using uv for fast dependency management:</p>"},{"location":"installation/#install-from-github","title":"Install from GitHub","text":"<p>To install the latest version directly from GitHub:</p> <pre><code>pip install git+https://github.com/SaarShafir/audio_signal.git\n</code></pre> <p>Or with uv:</p> <pre><code>uv pip install git+https://github.com/SaarShafir/audio_signal.git\n</code></pre>"},{"location":"installation/#install-from-pypi","title":"Install from PyPI","text":"<p>To install the latest release from PyPI:</p> <pre><code>pip install audio-signal\n</code></pre> <p>Or with uv:</p> <pre><code>uv pip install audio-signal\n</code></pre>"},{"location":"installation/#development-setup","title":"Development Setup","text":"<p>To set up a development environment:</p> <pre><code>git clone https://github.com/SaarShafir/audio_signal.git\ncd audio_signal\npip install -e .[dev]\n</code></pre> <p>Or with uv:</p> <pre><code>uv pip install -e .[dev]\n</code></pre>"},{"location":"installation/#troubleshooting","title":"Troubleshooting","text":"<ul> <li>Ensure you are using Python 3.7 or newer.</li> <li>If you encounter permission errors, try adding <code>--user</code> to the pip command.</li> <li>For issues with <code>uv</code>, see the uv documentation.</li> <li>If you have problems installing dependencies, try upgrading pip:</li> </ul> <pre><code>pip install --upgrade pip\n</code></pre> <p>For further help, open an issue on GitHub.</p>"},{"location":"usage/","title":"Basic Usage","text":""},{"location":"usage/#generate-and-play-a-sine-wave","title":"Generate and play a sine wave","text":"<pre><code>from audio_signal.core import AudioSignal\nsig = AudioSignal.wave(freq=440, time=2, sr=16000)\nsig.play()\n</code></pre>"},{"location":"usage/#load-from-file","title":"Load from file","text":"<pre><code>from audio_signal.core import AudioSignal\nsig = AudioSignal('audio.wav', sample_rate=16000)\n</code></pre>"},{"location":"usage/#save-to-file","title":"Save to file","text":"<pre><code>sig.save('output.wav')\n</code></pre>"},{"location":"usage/#change-playback-speed","title":"Change playback speed","text":"<pre><code>sig_fast = sig.clone().speed(1.5)  # 1.5x faster\nsig_fast.play()\n</code></pre>"},{"location":"usage/#convolve-and-correlate","title":"Convolve and correlate","text":"<pre><code>import torch\nkernel = torch.ones(1, 100) / 100  # simple moving average filter\n\nconvolved = sig.convolve(kernel)\ncorrelated = sig.correlate(kernel)\n</code></pre>"},{"location":"usage/#basic-usage_1","title":"Basic Usage","text":""},{"location":"usage/#audiosignal-is-a-torchtensor","title":"AudioSignal IS a torch.Tensor","text":"<pre><code>from matplotlib import pyplot as plt\n\na = AudioSignal.wave(1000,1,8000)\nb = AudioSignal.wave(2000,1,8000)\nc = torch.hstack([a,b])\nprint(c.sample_rate)\n\nspectrogram = torch.stft(c,256,return_complex=True).abs()\nplt.figure(figsize=(5,10))\nplt.imshow(spectrogram[0])\nplt.show()\n</code></pre>"},{"location":"usage/#use-it-for-every-torch-compatible-operation-including-nn","title":"Use it for every torch compatible operation (including nn)","text":"<p>here is a small convnet taking an AudioSignal as input</p> <pre><code>from torch import nn\n# from audio_signal import AudioSignal\n\nclass ConvBlock(nn.Module):\n  def __init__(self):\n    super().__init__()\n\n    self.conv = nn.Conv1d(1,1,3,1,1)\n    self.bn = nn.BatchNorm1d(1)\n    self.relu = nn.ReLU()\n    self.pool = nn.MaxPool1d(2)\n  def forward(self,x):\n    x = self.conv(x)\n    x = self.bn(x)\n    x = self.relu(x)\n    x = self.pool(x)\n    return x\n\na = AudioSignal.wave(1000,1,8000)\nmodel = ConvBlock()\nmodel(a.unsqueeze(0)).shape\n# torch.Size([1, 1, 4000])\n</code></pre>"}]}